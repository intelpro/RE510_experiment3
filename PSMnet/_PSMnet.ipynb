{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.11"
    },
    "colab": {
      "name": "PSMnet.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE4k3VftT2IM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/intelpro/Samsung_TAsession/\n",
        "%cd /contet/Samsung_TAsession/PSMnet/\n",
        "!ls\n",
        "!mkdir saved_model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "datapath = '/content/gdrive/My Drive/samsung_TAsession/KITTI_2015/training/'\n",
        "savemodel = './saved_model'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-gHKM74T2IQ",
        "colab_type": "text"
      },
      "source": [
        "## import로 모듈 가져오기\n",
        "### torch에 있는 module, 우리가 사전에 정의해놓았던 함수 등 import로 가져온다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbOGXR5UT2IR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function \n",
        "import torch \n",
        "import torch.nn as nn \n",
        "import torch.utils.data \n",
        "from torch.autograd import Variable \n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from submodule import *\n",
        "from preprocess import *\n",
        "from dataloader import listflowfile as lt\n",
        "from dataloader.KITTILoader import *\n",
        "from dataloader.KITTIloader2015 import *"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXwVHTYtUzA6",
        "colab_type": "text"
      },
      "source": [
        "## Feature extractor 정의하기 \n",
        "### 이미지에 feature를 뽑는 함수를 정의해봅니다. \n",
        "### 그중에서도 우리가 구현할 것은 Spatial pyramid pooling module입니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9czFGtMIU0Dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convbn(in_planes, out_planes, kernel_size, stride, pad, dilation):\n",
        "    return nn.Sequential(nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=dilation if dilation > 1 else pad, dilation = dilation, bias=False), \\\n",
        "                         nn.BatchNorm2d(out_planes))\n",
        "\n",
        "class feature_extraction(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(feature_extraction, self).__init__()\n",
        "        self.inplanes = 32\n",
        "        self.firstconv = nn.Sequential(convbn(3, 32, 3, 2, 1, 1),\n",
        "                                       nn.ReLU(inplace=True),\n",
        "                                       convbn(32, 32, 3, 1, 1, 1),\n",
        "                                       nn.ReLU(inplace=True),\n",
        "                                       convbn(32, 32, 3, 1, 1, 1),\n",
        "                                       nn.ReLU(inplace=True))\n",
        "\n",
        "        self.layer1 = self._make_layer(BasicBlock, 32, 3, 1,1,1)\n",
        "        self.layer2 = self._make_layer(BasicBlock, 64, 16, 2,1,1) \n",
        "        self.layer3 = self._make_layer(BasicBlock, 128, 3, 1,1,1)\n",
        "        self.layer4 = self._make_layer(BasicBlock, 128, 3, 1,1,2)\n",
        "\n",
        "        ## Your implementation Here\n",
        "        self.branch1 = nn.Sequential(nn.AvgPool2d((None, None), stride=(None,None)),\n",
        "                                     convbn(128, 32, 1, 1, 0, 1),\n",
        "                                     nn.ReLU(inplace=True))\n",
        "\n",
        "        self.branch2 = nn.Sequential(nn.AvgPool2d((None, None), stride=(None,None)),\n",
        "                                     convbn(128, 32, 1, 1, 0, 1),\n",
        "                                     nn.ReLU(inplace=True))\n",
        "\n",
        "        self.branch3 = nn.Sequential(nn.AvgPool2d((None, None), stride=(None,None)),\n",
        "                                     convbn(128, 32, 1, 1, 0, 1),\n",
        "                                     nn.ReLU(inplace=True))\n",
        "\n",
        "        self.branch4 = nn.Sequential(nn.AvgPool2d((None, None), stride=(None,None)),\n",
        "                                     convbn(128, 32, 1, 1, 0, 1),\n",
        "                                     nn.ReLU(inplace=True))\n",
        "        ## Your implementation Here        \n",
        "\n",
        "        self.lastconv = nn.Sequential(convbn(320, 128, 3, 1, 1, 1),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Conv2d(128, 32, kernel_size=1, padding=0, stride = 1, bias=False))\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride, pad, dilation):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "           downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),)\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, pad, dilation))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes,1,None,pad,dilation))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output      = self.firstconv(x)\n",
        "        output      = self.layer1(output)\n",
        "        output_raw  = self.layer2(output)\n",
        "        output      = self.layer3(output_raw)\n",
        "        output_skip = self.layer4(output)\n",
        "\n",
        "\n",
        "        output_branch1 = self.branch1(output_skip)\n",
        "        output_branch1 = F.upsample(output_branch1, (output_skip.size()[2],output_skip.size()[3]),mode='bilinear')\n",
        "\n",
        "        output_branch2 = self.branch2(output_skip)\n",
        "        output_branch2 = F.upsample(output_branch2, (output_skip.size()[2],output_skip.size()[3]),mode='bilinear')\n",
        "\n",
        "        output_branch3 = self.branch3(output_skip)\n",
        "        output_branch3 = F.upsample(output_branch3, (output_skip.size()[2],output_skip.size()[3]),mode='bilinear')\n",
        "\n",
        "        output_branch4 = self.branch4(output_skip)\n",
        "        output_branch4 = F.upsample(output_branch4, (output_skip.size()[2],output_skip.size()[3]),mode='bilinear')\n",
        "\n",
        "        output_feature = torch.cat((output_raw, output_skip, output_branch4, output_branch3, output_branch2, output_branch1), 1)\n",
        "        output_feature = self.lastconv(output_feature)\n",
        "\n",
        "        return output_feature"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toAhm7XBT2IV",
        "colab_type": "text"
      },
      "source": [
        "## PSMnet\n",
        "### PSMnet 생성자 정의하기\n",
        "#### 1단계: feature extraction part 정의하기\n",
        "#### 2단계: 3D convolution part 정의하기\n",
        "#### 3단계: weight initialization 하기\n",
        "### PSMnet forward 함수 정의하기\n",
        "#### 1단계: left, right 이미지에서 feature extraction을 수행한다. \n",
        "#### 2단계: cost volume을 만든다.  + left, right feature map을 cost volume의 형태에 맞게 만들어준다\n",
        "#### 3단계: 3D convolution을 통해서 cost volume의 refinement를 수행한다. \n",
        "#### 4단계: disparity regression을 수행한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03WscZdCT2IV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PSMNet(nn.Module):\n",
        "    def __init__(self, maxdisp):\n",
        "        super(PSMNet, self).__init__()\n",
        "        self.maxdisp = maxdisp\n",
        "        ############# 1단계: feature extraction part 정의하기 #############\n",
        "        self.feature_extraction = feature_extraction()\n",
        "        ############# 1단계 end #############\n",
        "        ############# 2단계: 3D convolution part 정의하기 #############\n",
        "        self.dres0 = nn.Sequential(convbn_3d(64, 32, 3, 1, 1),\n",
        "                                   nn.ReLU(inplace=True),\n",
        "                                   convbn_3d(32, 32, 3, 1, 1),\n",
        "                                   nn.ReLU(inplace=True))\n",
        "\n",
        "        self.dres1 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
        "                                   nn.ReLU(inplace=True),\n",
        "                                   convbn_3d(32, 32, 3, 1, 1)) \n",
        "\n",
        "        self.dres2 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
        "                                   nn.ReLU(inplace=True),\n",
        "                                   convbn_3d(32, 32, 3, 1, 1))\n",
        " \n",
        "        self.dres3 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
        "                                   nn.ReLU(inplace=True),\n",
        "                                   convbn_3d(32, 32, 3, 1, 1)) \n",
        "\n",
        "        self.dres4 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
        "                                   nn.ReLU(inplace=True),\n",
        "                                   convbn_3d(32, 32, 3, 1, 1)) \n",
        " \n",
        "        self.classify = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Conv3d(32, 1, kernel_size=3, padding=1, stride=1,bias=False))\n",
        "        ############ 2단계 end ###########\n",
        "        ############# 3단계: weight initialization #############\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.Conv3d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1]*m.kernel_size[2] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm3d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.bias.data.zero_()\n",
        "        ############# 3단계 end #############\n",
        "        \n",
        "    #### forward 함수 정의하기 ####\n",
        "    def forward(self, left, right):\n",
        "        ############# 1단계: left, right image로 부터 각각 feature extraction을 수행한다. #############\n",
        "        refimg_fea     = self.feature_extraction(left)\n",
        "        targetimg_fea  = self.feature_extraction(right)\n",
        " \n",
        "        ############# 2단계: cost volume을 만든다. #############\n",
        "        ############# cost volume의 사이즈는 Batch size x 2*Feature map size, disparity range/4, W, H #############\n",
        "        cost = Variable(torch.FloatTensor(refimg_fea.size()[0], refimg_fea.size()[1]*2, self.maxdisp//4,  \\\n",
        "                                          refimg_fea.size()[2],  refimg_fea.size()[3]).zero_(), \\\n",
        "                                          volatile= not self.training).cuda()\n",
        "        ############# 2단계: left, right feature map을 cost volume의 형태에 맞게 만들어준다. #############\n",
        "        ############# 5D cost volume에서 두번째 차원(Feature map size)의 한쪽에는 reference image #############\n",
        "        ############# 다른 한쪽에서는 target image를 넣어준다. #############\n",
        "\n",
        "        for i in range(self.maxdisp//4):\n",
        "            if i > 0 :\n",
        "                cost[:, :refimg_fea.size()[1], i, :,i:]   = refimg_fea[:,:,:,i:]\n",
        "                cost[:, refimg_fea.size()[1]:, i, :,i:] = targetimg_fea[:,:,:,:-i]\n",
        "            else:\n",
        "                cost[:, :refimg_fea.size()[1], i, :,:]   = refimg_fea\n",
        "                cost[:, refimg_fea.size()[1]:, i, :,:]   = targetimg_fea\n",
        "        ############# 3단계: cost volume의 refinement를 수행한다. #############\n",
        "        cost = cost.contiguous()\n",
        "\n",
        "        cost0 = self.dres0(cost)\n",
        "        cost0 = self.dres1(cost0) + cost0\n",
        "        cost0 = self.dres2(cost0) + cost0 \n",
        "        cost0 = self.dres3(cost0) + cost0 \n",
        "        cost0 = self.dres4(cost0) + cost0\n",
        "        ############# 4단계: disparity regression을 수행한다. #############\n",
        "        cost = self.classify(cost0)\n",
        "        cost = F.upsample(cost, [self.maxdisp,left.size()[2],left.size()[3]], mode='trilinear')\n",
        "        cost = torch.squeeze(cost,1)\n",
        "        pred = F.softmax(cost)\n",
        "        pred = disparityregression(self.maxdisp)(pred)\n",
        "        return pred"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy6vKEU9T2IZ",
        "colab_type": "text"
      },
      "source": [
        "## main 함수\n",
        "### 각종 hyperparameter들과 dataset 경로들을 지정한다. \n",
        "### model을 정의하고 gpu상에 올려준다. \n",
        "### optimizer를 정의한다. \n",
        "### model을 print하면 우리가 정의했던 model들의 module들을 볼 수 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "YNRoOqILT2Ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__=='__main__':\n",
        "    max_disp = 192\n",
        "    epochs = 20\n",
        "    model = PSMNet(max_disp)\n",
        "    model = model.cuda()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
        "    print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSOkae7-T2Ie",
        "colab_type": "text"
      },
      "source": [
        "## Get dataset string\n",
        "### data path 내에 있는 left image, right image, disparity 등의 string을 가져온다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f541QuYoT2Ig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    all_left_img, all_right_img, all_left_disp, test_left_img, test_right_img, test_left_disp = dataloader(datapath)\n",
        "    print('left image string:', all_left_img[0])\n",
        "    print('right image string: ', all_right_img[0])\n",
        "    print('left disparity string: ', all_left_disp[0])\n",
        "    print('test left image string: ',test_left_img[0])\n",
        "    print('test right image string: ', test_right_img[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U_sQfjMT2Ik",
        "colab_type": "text"
      },
      "source": [
        "## Define dataloader\n",
        "### image string정보를 사용하여 dataloader를 정의한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL8OYLq0T2Il",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    KITTI_dataset_train = myImageFloder(all_left_img,all_right_img,all_left_disp, True)\n",
        "    TrainImgLoader = torch.utils.data.DataLoader(KITTI_dataset_train, \n",
        "         batch_size= 3, shuffle= True, num_workers= 8, drop_last=False)\n",
        "    print('Train object: ', TrainImgLoader)\n",
        "    KITTI_dataset_test = myImageFloder(test_left_img, test_right_img, test_left_disp, True)\n",
        "    TestImgLoader = torch.utils.data.DataLoader(KITTI_dataset_test, \\\n",
        "                    batch_size=8, shuffle= False, num_workers= 4, drop_last=False)\n",
        "    print('Test object: ', TestImgLoader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unxxcKbmT2Iq",
        "colab_type": "text"
      },
      "source": [
        "## Check KITTI dataset data\n",
        "### 우리가 정의한 KITTI dataset 정보를 사용하여 image들을 plot 해봅니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyJBLu1gT2Iq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    left_img, right_img, left_disp = KITTI_dataset_train.__getitem__(0)\n",
        "    plt.figure()\n",
        "    plt.title('left image')\n",
        "    plt.imshow(left_img.detach().cpu().numpy().transpose(1,2,0))\n",
        "    plt.figure()\n",
        "    plt.title('right image')\n",
        "    plt.imshow(right_img.detach().cpu().numpy().transpose(1,2,0))\n",
        "    plt.figure()\n",
        "    plt.title('left disparity')\n",
        "    plt.imshow(left_disp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3O5KO92T2Iv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    for epoch in range(0, epochs):\n",
        "        total_train_loss = 0\n",
        "        print('This is %d-th epoch' %(epoch))\n",
        "        model.train()\n",
        "        #------------- Train ------------------------------------------------------------\n",
        "        for batch_idx, (imgL_crop, imgR_crop, disp_crop_L) in enumerate(TrainImgLoader):\n",
        "            imgL_crop, imgR_crop, disp_crop_L = imgL_crop.cuda(), imgR_crop.cuda(), disp_crop_L.cuda()\n",
        "            mask = disp_crop_L < max_disp\n",
        "            mask.detach_()\n",
        "            start_time = time.time()\n",
        "            output = model(imgL_crop, imgR_crop)\n",
        "            output = torch.squeeze(output,1)\n",
        "            loss = F.smooth_l1_loss(output[mask], disp_crop_L[mask], size_average=True)\n",
        "            loss.backward()\n",
        "            total_train_loss += loss.detach().item()\n",
        "            optimizer.step()\n",
        "            if batch_idx % 3 == 0:\n",
        "                print('Iter %d training loss = %.3f , time = %.2f' %(batch_idx, loss, time.time() - start_time))\n",
        "        print('epoch %d total training loss = %.3f' %(epoch, total_train_loss/len(TrainImgLoader)))\n",
        "        #SAVE\n",
        "        savefilename = savemodel+'/checkpoint_'+str(epoch)+'.tar'\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'train_loss': total_train_loss/len(TrainImgLoader),\n",
        "         }, savefilename)\n",
        "        #------------- TEST ------------------------------------------------------------\n",
        "        total_test_loss = 0\n",
        "        for batch_idx, (imgL, imgR, disp_L) in enumerate(TestImgLoader):\n",
        "            test_loss, disp = test(model, imgL,imgR, disp_L)\n",
        "            print('Iter %d test loss = %.3f' %(batch_idx, test_loss))\n",
        "            total_test_loss += test_loss\n",
        "        print('total test loss = %.3f' %(total_test_loss/len(TestImgLoader)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}