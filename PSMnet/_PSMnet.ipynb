{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.11"
    },
    "colab": {
      "name": "PSMnet.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3VDN0rKNZFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/intelpro/Samsung_TAsession/\n",
        "%cd /content/Samsung_TAsession/PSMnet/\n",
        "!ls\n",
        "!mkdir saved_model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "datapath = '/content/gdrive/My Drive/samsung_TAsession/KITTI_2015/training/'\n",
        "savemodel = './saved_model'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRTl7SsaNZFx",
        "colab_type": "text"
      },
      "source": [
        "## import로 모듈 가져오기\n",
        "### torch에 있는 module, 우리가 사전에 정의해놓았던 함수 등 import로 가져온다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEhOSwtfNZFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function \n",
        "import torch \n",
        "import torch.nn as nn \n",
        "import torch.utils.data \n",
        "from torch.autograd import Variable \n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from submodule import *\n",
        "from preprocess import *\n",
        "from dataloader import listflowfile as lt\n",
        "from dataloader.KITTILoader import *\n",
        "from dataloader.KITTIloader2015 import *"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzcQsp0SNZF8",
        "colab_type": "text"
      },
      "source": [
        "## Get dataset string\n",
        "### data path 내에 있는 left image, right image, disparity 등의 string을 가져온다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7afvyloJNZF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_left_img, all_right_img, all_left_disp, test_left_img, test_right_img, test_left_disp = dataloader(datapath)\n",
        "print('left image string:', all_left_img[0])\n",
        "print('right image string: ', all_right_img[0])\n",
        "print('left disparity string: ', all_left_disp[0])\n",
        "print('test left image string: ',test_left_img[0])\n",
        "print('test right image string: ', test_right_img[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKy9vHUkNZF_",
        "colab_type": "text"
      },
      "source": [
        "## Define dataloader\n",
        "### image string정보를 사용하여 dataloader를 정의한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE8AT1rdNZF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "KITTI_dataset_train = myImageFloder(all_left_img,all_right_img,all_left_disp, True)\n",
        "TrainImgLoader = torch.utils.data.DataLoader(KITTI_dataset_train, \n",
        "      batch_size= 2, shuffle= True, num_workers= 8, drop_last=False)\n",
        "print('Train object: ', TrainImgLoader)\n",
        "KITTI_dataset_test = myImageFloder(test_left_img, test_right_img, test_left_disp, True)\n",
        "TestImgLoader = torch.utils.data.DataLoader(KITTI_dataset_test, \\\n",
        "                batch_size=8, shuffle= False, num_workers= 4, drop_last=False)\n",
        "print('Test object: ', TestImgLoader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iATBEOIUNZGC",
        "colab_type": "text"
      },
      "source": [
        "## Check KITTI dataset data\n",
        "### 우리가 정의한 KITTI dataset 정보를 사용하여 image들을 plot 해봅니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNMI3KBXNZGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "left_img, right_img, left_disp = KITTI_dataset_train.__getitem__(0)\n",
        "plt.figure()\n",
        "plt.title('left image')\n",
        "plt.imshow(left_img.detach().cpu().numpy().transpose(1,2,0))\n",
        "plt.figure()\n",
        "plt.title('right image')\n",
        "plt.imshow(right_img.detach().cpu().numpy().transpose(1,2,0))\n",
        "plt.figure()\n",
        "plt.title('ground truth left disparity')\n",
        "plt.imshow(left_disp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrZ0754qNrUq",
        "colab_type": "text"
      },
      "source": [
        "## Feature extractor 정의하기 \n",
        "### 이미지에 feature를 뽑는 함수를 정의해봅니다. \n",
        "### 그중에서도 우리가 구현할 것은 Spatial pyramid pooling module입니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-eQvqBwN4XI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convbn(in_planes, out_planes, kernel_size, stride, pad, dilation):\n",
        "    return nn.Sequential(nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=dilation if dilation > 1 else pad, dilation = dilation, bias=False), \\\n",
        "                         nn.BatchNorm2d(out_planes))\n",
        "\n",
        "class feature_extraction(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(feature_extraction, self).__init__()\n",
        "        self.inplanes = 32\n",
        "        self.firstconv = nn.Sequential(convbn(3, 32, 3, 2, 1, 1),\n",
        "                                       nn.ReLU(inplace=True),\n",
        "                                       convbn(32, 32, 3, 1, 1, 1),\n",
        "                                       nn.ReLU(inplace=True),\n",
        "                                       convbn(32, 32, 3, 1, 1, 1),\n",
        "                                       nn.ReLU(inplace=True))\n",
        "\n",
        "        self.layer1 = self._make_layer(BasicBlock, 32, 3, 1,1,1)\n",
        "        self.layer2 = self._make_layer(BasicBlock, 64, 16, 2,1,1) \n",
        "        self.layer3 = self._make_layer(BasicBlock, 128, 3, 1,1,1)\n",
        "        self.layer4 = self._make_layer(BasicBlock, 128, 3, 1,1,2)\n",
        "\n",
        "        ## Your implementation Here\n",
        "        self.branch1 = nn.Sequential(nn.AvgPool2d((None, None), stride=(None,None)),\n",
        "                                     convbn(None, None, 1, 1, 0, 1),\n",
        "                                     nn.ReLU(inplace=True))\n",
        "\n",
        "        self.branch2 = nn.Sequential(nn.AvgPool2d((None, None), stride=(None,None)),\n",
        "                                     convbn(None, None, 1, 1, 0, 1),\n",
        "                                     nn.ReLU(inplace=True))\n",
        "\n",
        "        self.branch3 = nn.Sequential(nn.AvgPool2d((None, None), stride=(None,None)),\n",
        "                                     convbn(None, None, 1, 1, 0, 1),\n",
        "                                     nn.ReLU(inplace=True))\n",
        "\n",
        "        self.branch4 = nn.Sequential(nn.AvgPool2d((None, None), stride=(None,None)),\n",
        "                                     convbn(None, None, 1, 1, 0, 1),\n",
        "                                     nn.ReLU(inplace=True))\n",
        "        ## Your implementation end        \n",
        "\n",
        "        self.lastconv = nn.Sequential(convbn(320, 128, 3, 1, 1, 1),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Conv2d(128, 32, kernel_size=1, padding=0, stride = 1, bias=False))\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride, pad, dilation):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "           downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),)\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, pad, dilation))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes,1,None,pad,dilation))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output      = self.firstconv(x)\n",
        "        output      = self.layer1(output)\n",
        "        output_raw  = self.layer2(output)\n",
        "        output      = self.layer3(output_raw)\n",
        "        output_skip = self.layer4(output)\n",
        "\n",
        "\n",
        "        output_branch1 = self.branch1(output_skip)\n",
        "        output_branch1 = F.upsample(output_branch1, (output_skip.size()[2],output_skip.size()[3]),mode='bilinear')\n",
        "\n",
        "        output_branch2 = self.branch2(output_skip)\n",
        "        output_branch2 = F.upsample(output_branch2, (output_skip.size()[2],output_skip.size()[3]),mode='bilinear')\n",
        "\n",
        "        output_branch3 = self.branch3(output_skip)\n",
        "        output_branch3 = F.upsample(output_branch3, (output_skip.size()[2],output_skip.size()[3]),mode='bilinear')\n",
        "\n",
        "        output_branch4 = self.branch4(output_skip)\n",
        "        output_branch4 = F.upsample(output_branch4, (output_skip.size()[2],output_skip.size()[3]),mode='bilinear')\n",
        "\n",
        "        output_feature = torch.cat((output_raw, output_skip, output_branch4, output_branch3, output_branch2, output_branch1), 1)\n",
        "        output_feature = self.lastconv(output_feature)\n",
        "\n",
        "        return output_feature"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEGL3J7eNZF0",
        "colab_type": "text"
      },
      "source": [
        "## PSMnet\n",
        "### PSMnet 생성자 정의하기\n",
        "#### 1단계: feature extraction part 정의하기\n",
        "#### 2단계: 3D convolution part 정의하기\n",
        "#### 3단계: weight initialization 하기\n",
        "### PSMnet forward 함수 정의하기\n",
        "#### 1단계: left, right 이미지에서 feature extraction을 수행한다. \n",
        "#### 2단계: cost volume을 만든다.  + left, right feature map을 cost volume의 형태에 맞게 만들어준다\n",
        "#### 3단계: 3D convolution을 통해서 cost volume의 refinement를 수행한다. \n",
        "#### 4단계: disparity regression을 수행한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VpDx9EXNZF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PSMNet(nn.Module):\n",
        "    def __init__(self, maxdisp):\n",
        "        super(PSMNet, self).__init__()\n",
        "        self.maxdisp = maxdisp\n",
        "\n",
        "        self.feature_extraction = feature_extraction()\n",
        "\n",
        "        self.dres0 = nn.Sequential(convbn_3d(64, 32, 3, 1, 1),\n",
        "                                     nn.ReLU(inplace=True),\n",
        "                                     convbn_3d(32, 32, 3, 1, 1),\n",
        "                                     nn.ReLU(inplace=True))\n",
        "\n",
        "        self.dres1 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
        "                                   nn.ReLU(inplace=True),\n",
        "                                   convbn_3d(32, 32, 3, 1, 1)) \n",
        "\n",
        "        self.dres2 = hourglass(32)\n",
        "        self.dres3 = hourglass(32)\n",
        "        self.dres4 = hourglass(32)\n",
        "\n",
        "        self.classif1 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Conv3d(32, 1, kernel_size=3, padding=1, stride=1,bias=False))\n",
        "\n",
        "        self.classif2 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Conv3d(32, 1, kernel_size=3, padding=1, stride=1,bias=False))\n",
        "\n",
        "        self.classif3 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Conv3d(32, 1, kernel_size=3, padding=1, stride=1,bias=False))\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.Conv3d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1]*m.kernel_size[2] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm3d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "\n",
        "    def forward(self, left, right):\n",
        "\n",
        "        refimg_fea     = self.feature_extraction(left)\n",
        "        targetimg_fea  = self.feature_extraction(right)\n",
        "\n",
        "\n",
        "        #matching\n",
        "        cost = Variable(torch.FloatTensor(refimg_fea.size()[0], refimg_fea.size()[1]*2, self.maxdisp//4,  refimg_fea.size()[2],  refimg_fea.size()[3]).zero_()).cuda()\n",
        "\n",
        "        for i in range(self.maxdisp//4):\n",
        "            if i > 0 :\n",
        "             cost[:, :refimg_fea.size()[1], i, :,i:]   = refimg_fea[:,:,:,i:]\n",
        "             cost[:, refimg_fea.size()[1]:, i, :,i:] = targetimg_fea[:,:,:,:-i]\n",
        "            else:\n",
        "             cost[:, :refimg_fea.size()[1], i, :,:]   = refimg_fea\n",
        "             cost[:, refimg_fea.size()[1]:, i, :,:]   = targetimg_fea\n",
        "        cost = cost.contiguous()\n",
        "\n",
        "        cost0 = self.dres0(cost)\n",
        "        cost0 = self.dres1(cost0) + cost0\n",
        "\n",
        "        out1, pre1, post1 = self.dres2(cost0, None, None) \n",
        "        out1 = out1+cost0\n",
        "\n",
        "        out2, pre2, post2 = self.dres3(out1, pre1, post1) \n",
        "        out2 = out2+cost0\n",
        "\n",
        "        out3, pre3, post3 = self.dres4(out2, pre1, post2) \n",
        "        out3 = out3+cost0\n",
        "\n",
        "        cost1 = self.classif1(out1)\n",
        "        cost2 = self.classif2(out2) + cost1\n",
        "        cost3 = self.classif3(out3) + cost2\n",
        "        if self.training:\n",
        "          cost1 = F.upsample(cost1, [self.maxdisp,left.size()[2],left.size()[3]], mode='trilinear')\n",
        "          cost2 = F.upsample(cost2, [self.maxdisp,left.size()[2],left.size()[3]], mode='trilinear')\n",
        "\n",
        "          cost1 = torch.squeeze(cost1,1)\n",
        "          pred1 = F.softmax(cost1,dim=1)\n",
        "          pred1 = disparityregression(self.maxdisp)(pred1)\n",
        "\n",
        "          cost2 = torch.squeeze(cost2,1)\n",
        "          pred2 = F.softmax(cost2,dim=1)\n",
        "          pred2 = disparityregression(self.maxdisp)(pred2)\n",
        "\n",
        "        cost3 = F.upsample(cost3, [self.maxdisp,left.size()[2],left.size()[3]], mode='trilinear')\n",
        "        cost3 = torch.squeeze(cost3,1)\n",
        "        pred3 = F.softmax(cost3,dim=1)\n",
        "        #For your information: This formulation 'softmax(c)' learned \"similarity\" \n",
        "        #while 'softmax(-c)' learned 'matching cost' as mentioned in the paper.\n",
        "        #However, 'c' or '-c' do not affect the performance because feature-based cost volume provided flexibility.\n",
        "        pred3 = disparityregression(self.maxdisp)(pred3)\n",
        "\n",
        "        if self.training:\n",
        "            return pred1, pred2, pred3\n",
        "        else:\n",
        "            return pred3        "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyqpsr0hNZF4",
        "colab_type": "text"
      },
      "source": [
        "## main 함수\n",
        "### 각종 hyperparameter들과 dataset 경로들을 지정한다. \n",
        "### model을 정의하고 gpu상에 올려준다. \n",
        "### optimizer를 정의한다. \n",
        "### model을 print하면 우리가 정의했던 model들의 module들을 볼 수 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "V4F1bslkNZF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__=='__main__':\n",
        "    max_disp = 192\n",
        "    epochs = 1\n",
        "    model = PSMNet(max_disp)\n",
        "    model = model.cuda()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
        "    print(model.feature_extraction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn99TTQXYGDK",
        "colab_type": "text"
      },
      "source": [
        "## Training with KITTI dataset\n",
        "### 1 epoch동안 트레이닝을 수행합니다. \n",
        "### loss function으로는 smoothness L1 loss를 사용합니다.\n",
        "### training log를 보며 정상적으로 training loss가 줄어드는 것을 확인하세요. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3rJ-3m3NZGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    for epoch in range(0, epochs):\n",
        "        total_train_loss = 0\n",
        "        print('This is %d-th epoch' %(epoch))\n",
        "        model.train()\n",
        "        #------------- Train ------------------------------------------------------------\n",
        "        for batch_idx, (imgL_crop, imgR_crop, disp_crop_L) in enumerate(TrainImgLoader):\n",
        "            imgL_crop, imgR_crop, disp_crop_L = imgL_crop.cuda(), imgR_crop.cuda(), disp_crop_L.cuda()\n",
        "            mask = disp_crop_L < max_disp\n",
        "            mask.detach_()\n",
        "            start_time = time.time()\n",
        "            output = model(imgL_crop, imgR_crop)\n",
        "            loss = F.smooth_l1_loss(output[0][mask], disp_crop_L[mask], size_average=True)\n",
        "            loss.backward()\n",
        "            total_train_loss += loss.detach().item()\n",
        "            optimizer.step()\n",
        "            if batch_idx % 3 == 0:\n",
        "                print('Iter %d training loss = %.3f , time = %.2f' %(batch_idx, loss, time.time() - start_time))\n",
        "        print('epoch %d total training loss = %.3f' %(epoch, total_train_loss/len(TrainImgLoader)))\n",
        "        #SAVE\n",
        "        savefilename = savemodel+'/checkpoint_'+str(epoch)+'.tar'\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'train_loss': total_train_loss/len(TrainImgLoader),\n",
        "         }, savefilename)\n",
        "        #------------- TEST ------------------------------------------------------------\n",
        "        total_test_loss = 0\n",
        "        for batch_idx, (imgL, imgR, disp_L) in enumerate(TestImgLoader):\n",
        "            test_loss, disp = test(model, imgL,imgR, disp_L)\n",
        "            print('Iter %d test loss = %.3f' %(batch_idx, test_loss))\n",
        "            total_test_loss += test_loss\n",
        "        print('total test loss = %.3f' %(total_test_loss/len(TestImgLoader)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HkS7XCDZKm1",
        "colab_type": "text"
      },
      "source": [
        "## Test with KITTI test sample \n",
        "### Test set의 데이터를 사용하여 disparity 이미지를 출력해봅시다.\n",
        "### 트레이닝에 시간이 오래걸림으로 pretrianed model을 사용합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAAm_ISLZwe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "left_image_path = '/content/gdrive/My Drive/samsung_TAsession/KITTI_2015/testing/left.png'\n",
        "right_image_path = '/content/gdrive/My Drive/samsung_TAsession/KITTI_2015/testing/right.png'"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvoIWOdRZZyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def test_img(imgL,imgR):\n",
        "      model.eval()\n",
        "\n",
        "      imgL = imgL.cuda()\n",
        "      imgR = imgR.cuda()     \n",
        "\n",
        "      with torch.no_grad():\n",
        "          disp = model(imgL,imgR)\n",
        "\n",
        "      disp = torch.squeeze(disp)\n",
        "      pred_disp = disp.data.cpu().numpy()\n",
        "\n",
        "      return pred_disp\n",
        "if __name__=='__main__':\n",
        "    from collections import OrderedDict\n",
        "    checkpoint = torch.load('/content/gdrive/My Drive/samsung_TAsession/pretrained_model_KITTI2015.tar')\n",
        "    new_state_dict = OrderedDict()\n",
        "    for k, v in checkpoint['state_dict'].items():\n",
        "        name = k[7:]\n",
        "        new_state_dict[name] = v    \n",
        "    model.load_state_dict(new_state_dict)    \n",
        "    normal_mean_var = {'mean': [0.485, 0.456, 0.406],\n",
        "                        'std': [0.229, 0.224, 0.225]}\n",
        "    infer_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                          transforms.Normalize(**normal_mean_var)])    \n",
        "\n",
        "    imgL_o = Image.open(left_image_path).convert('RGB')\n",
        "    imgR_o = Image.open(right_image_path).convert('RGB')\n",
        "\n",
        "    imgL = infer_transform(imgL_o)\n",
        "    imgR = infer_transform(imgR_o) \n",
        "\n",
        "    # pad to width and hight to 16 times\n",
        "    if imgL.shape[1] % 16 != 0:\n",
        "        times = imgL.shape[1]//16       \n",
        "        top_pad = (times+1)*16 -imgL.shape[1]\n",
        "    else:\n",
        "        top_pad = 0\n",
        "\n",
        "    if imgL.shape[2] % 16 != 0:\n",
        "        times = imgL.shape[2]//16                       \n",
        "        right_pad = (times+1)*16-imgL.shape[2]\n",
        "    else:\n",
        "        right_pad = 0    \n",
        "\n",
        "    imgL = F.pad(imgL,(0,right_pad, top_pad,0)).unsqueeze(0)\n",
        "    imgR = F.pad(imgR,(0,right_pad, top_pad,0)).unsqueeze(0)\n",
        "\n",
        "    start_time = time.time()\n",
        "    pred_disp = test_img(imgL,imgR)\n",
        "    if top_pad !=0 or right_pad != 0:\n",
        "      img = pred_disp[top_pad:,:-right_pad]\n",
        "    else:\n",
        "      img = pred_disp\n",
        "    plt.figure()\n",
        "    plt.title('left image')\n",
        "    plt.imshow(imgL_o)\n",
        "    plt.figure()\n",
        "    plt.title('disparity output')\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    print('time = %.2f' %(time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}